{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## p3. 完成LunaDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../../src/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from util.logconf import logging\n",
    "from util.util import XyzTuple, xyz2irc\n",
    "from collections import namedtuple, defaultdict\n",
    "import csv\n",
    "import glob\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import os\n",
    "import pandas as pd\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = logging.getLogger(__name__)\n",
    "# log.setLevel(logging.WARN)\n",
    "# log.setLevel(logging.INFO)\n",
    "log.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "CandidateInfoTuple = namedtuple(\n",
    "    \"CandidateInfoTuple\",\n",
    "    \"is_nodule, diameter_mm, series_uid, center_xyz\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"D:/Code/data/luna16/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCandidateInfoList(require_on_disk_bool=True):\n",
    "    # 开始时不把所有的数据都解压，这里只取了部分subset，所以需要判断一下路径下真正存在的subset\n",
    "    mhd_list = glob.glob(path + \"subset*/*.mhd\")\n",
    "    present_on_disk_set = {os.path.split(p)[-1][:-4] for p in mhd_list}\n",
    "\n",
    "    diameter_dict = defaultdict(list)\n",
    "    annotations_df = pd.read_csv(path + \"annotations.csv\")\n",
    "    for _, row_series in annotations_df.iterrows():\n",
    "        row_list = row_series.tolist()\n",
    "        series_uid = row_list[0]\n",
    "        annotation_center_xyz = tuple([float(x) for x in row_list[1:4]])\n",
    "        annotation_diameter_mm = float(row_list[4])\n",
    "        diameter_dict[series_uid].append(\n",
    "            (annotation_center_xyz, annotation_diameter_mm)\n",
    "        )\n",
    "\n",
    "    candidate_info_list = []\n",
    "    candidate_df = pd.read_csv(path + \"candidates.csv\")\n",
    "    for _, row_series in candidate_df.iterrows():\n",
    "        row_list = row_series.tolist()\n",
    "        series_uid = row_list[0]\n",
    "        if series_uid not in present_on_disk_set and require_on_disk_bool:\n",
    "            continue\n",
    "\n",
    "        is_nodule = bool(int(row_list[4]))\n",
    "        candidate_center_xyz = tuple([float(x) for x in row_list[1:4]])\n",
    "\n",
    "        candidate_diameter_mm = 0.0\n",
    "        # 因为上面使用了defaultdict，所以这里不需要判断series_uid是否在diameter_dict中\n",
    "        # 这里对比了候选结节的中心点和直径与annotations.csv中的中心点和直径，如果候选结节的中心点和直径在annotations.csv中的中心点和直径的1/4范围内，则认为是同一个结节\n",
    "        # 就可以得到候选结节的直径\n",
    "        # 至于不在1/4范围内的候选结节，直径就是0.0\n",
    "        for annotation_tuple in diameter_dict[series_uid]:\n",
    "            annotation_center_xyz, annotation_diameter_mm = annotation_tuple\n",
    "            for i in range(3):\n",
    "                delta_mm = abs(candidate_center_xyz[i] - annotation_center_xyz[i])\n",
    "                if delta_mm > annotation_diameter_mm / 4:\n",
    "                    break\n",
    "            else:\n",
    "                candidate_diameter_mm = annotation_diameter_mm\n",
    "                break\n",
    "\n",
    "        candidate_info_list.append(\n",
    "            CandidateInfoTuple(\n",
    "                is_nodule,\n",
    "                candidate_diameter_mm,\n",
    "                series_uid,\n",
    "                candidate_center_xyz,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # namedtuple之间的比较是按照顺序比较的，所以这里是先按照is_nodule是不是结节排序(分组)，而True>False，\n",
    "    # 所以靠前的都是结节，如果is_nodule相同，那么就按照diameter_mm降序排列\n",
    "    candidate_info_list.sort(reverse=True)\n",
    "    return candidate_info_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(True < False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ct:\n",
    "    def __init__(self, series_uid):\n",
    "        # 指定series_uid，找到对应的mhd文件\n",
    "        mhd_path = glob.glob(path + f\"subset*/{series_uid}.mhd\")[0]\n",
    "\n",
    "        ct_mhd = sitk.ReadImage(mhd_path)\n",
    "        ct_arr = np.array(sitk.GetArrayFromImage(ct_mhd), dtype=np.float32)\n",
    "\n",
    "        # 限制HU值的范围，因为一般空气的HU值在-1000左右，骨头的HU值在1000左右\n",
    "        ct_arr.clip(-1000, 1000, ct_arr)\n",
    "\n",
    "        self.series_uid = series_uid\n",
    "        self.hu_arr = ct_arr\n",
    "\n",
    "        self.origin_xyz = XyzTuple(*ct_mhd.GetOrigin())\n",
    "        self.vxSize_xyz = XyzTuple(*ct_mhd.GetSpacing())\n",
    "        self.direction_arr = np.array(ct_mhd.GetDirection()).reshape(3, 3)\n",
    "\n",
    "    def getRawCandidate(self, center_xyz, width_irc):\n",
    "        center_irc = xyz2irc(\n",
    "            center_xyz,\n",
    "            self.origin_xyz,\n",
    "            self.vxSize_xyz,\n",
    "            self.direction_arr,\n",
    "        )\n",
    "\n",
    "        slice_list = []\n",
    "        for axis, center_val in enumerate(center_irc):\n",
    "            start_idx = int(round(center_val - width_irc[axis] / 2))\n",
    "            end_idx = int(start_idx + width_irc[axis])\n",
    "\n",
    "            assert center_val >= 0 and center_val < self.hu_arr.shape[axis], repr(\n",
    "                [\n",
    "                    self.series_uid,\n",
    "                    center_xyz,\n",
    "                    self.origin_xyz,\n",
    "                    self.vxSize_xyz,\n",
    "                    center_irc,\n",
    "                    axis,\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            # 处理候选结节可能超出CT边界的情况\n",
    "            if start_idx < 0:\n",
    "                # log.warning(\"Crop outside of CT array: {} {}, center:{} shape:{} width:{}\".format(\n",
    "                #     self.series_uid, center_xyz, center_irc, self.hu_a.shape, width_irc))\n",
    "                start_idx = 0\n",
    "                end_idx = int(width_irc[axis])\n",
    "\n",
    "            if end_idx > self.hu_arr.shape[axis]:\n",
    "                # log.warning(\"Crop outside of CT array: {} {}, center:{} shape:{} width:{}\".format(\n",
    "                #     self.series_uid, center_xyz, center_irc, self.hu_a.shape, width_irc))\n",
    "                end_idx = self.hu_arr.shape[axis]\n",
    "                start_idx = int(self.hu_arr.shape[axis] - width_irc[axis])\n",
    "\n",
    "            slice_list.append(slice(start_idx, end_idx))\n",
    "\n",
    "        ct_chunk = self.hu_arr[tuple(slice_list)]\n",
    "\n",
    "        return ct_chunk, center_irc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCt(series_uid):\n",
    "    return Ct(series_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCtRawCandidate(series_uid, center_xyz, width_irc):\n",
    "    ct = getCt(series_uid)\n",
    "    ct_chunk, center_irc = ct.getRawCandidate(center_xyz, width_irc)\n",
    "    return ct_chunk, center_irc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LunaDataset(Dataset):\n",
    "    # is_val指定是否用来测试，val_stride指定测试集集的步长\n",
    "    def __init__(self, val_stride=0, is_val=None, series_uid=None):\n",
    "        self.candidate_info_list = copy.copy(getCandidateInfoList())\n",
    "\n",
    "        if series_uid:\n",
    "            self.candidate_info_list = [\n",
    "                x for x in self.candidate_info_list if x.series_uid == series_uid\n",
    "            ]\n",
    "\n",
    "        # 分割数据集\n",
    "        if is_val:\n",
    "            assert val_stride > 0, val_stride\n",
    "            self.candidate_info_list = self.candidate_info_list[::val_stride]\n",
    "            assert self.candidate_info_list\n",
    "        elif val_stride > 0:\n",
    "            del self.candidate_info_list[::val_stride]\n",
    "            assert self.candidate_info_list\n",
    "\n",
    "        log.info(f\"{repr(self)}: {len(self.candidate_info_list)} {\"validation\" if is_val else \"training\"} samples\")\n",
    "        \n",
    "        # log.info(\n",
    "        #     \"{!r}: {} {} samples\".format(\n",
    "        #         self,\n",
    "        #         len(self.candidate_info_list),\n",
    "        #         \"validation\" if is_val else \"training\",\n",
    "        #     )\n",
    "        # )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.candidate_info_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        candidate_info_tuple = self.candidate_info_list[idx]\n",
    "        # 预设的候选结节的尺寸\n",
    "        width_irc = (32, 48, 48)\n",
    "\n",
    "        candidate_arr, center_irc = getCtRawCandidate(\n",
    "            candidate_info_tuple.series_uid,\n",
    "            candidate_info_tuple.center_xyz,\n",
    "            width_irc,\n",
    "        )\n",
    "\n",
    "        candidate_t = torch.from_numpy(candidate_arr).to(torch.float32).unsqueeze(0)\n",
    "\n",
    "        logits = torch.tensor(\n",
    "            [\n",
    "                not candidate_info_tuple.is_nodule,\n",
    "                candidate_info_tuple.is_nodule,\n",
    "            ],\n",
    "            dtype=torch.int64,\n",
    "        )\n",
    "\n",
    "        return (\n",
    "            candidate_t,\n",
    "            logits,\n",
    "            candidate_info_tuple.series_uid,\n",
    "            torch.tensor(center_irc),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-28 11:15:11,068 INFO     pid:27028 __main__:019:__init__ <__main__.LunaDataset object at 0x0000017D769818E0>: 110143 training samples\n"
     ]
    }
   ],
   "source": [
    "# ds = LunaDataset(series_uid=\"1.3.6.1.4.1.14519.5.2.1.6279.6001.100684836163890911914061745866\")\n",
    "ds = LunaDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 32, 48, 48]),\n",
       " tensor([0, 1]),\n",
       " '1.3.6.1.4.1.14519.5.2.1.6279.6001.287966244644280690737019247886',\n",
       " tensor([ 91, 360, 341]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0][0].shape, ds[0][1], ds[0][2], ds[0][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**需要注意的是，由于上面candidate_info_list的排序方式，有可能许多相同uid的ct数据会连续，这时需要考虑一个问题就是，是否不能让同一个uid的ct数据同时出现在训练集与测试集中，以防出现数据泄露的情况**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.3.6.1.4.1.14519.5.2.1.6279.6001.287966244644280690737019247886',\n",
       " '1.3.6.1.4.1.14519.5.2.1.6279.6001.511347030803753100045216493273',\n",
       " '1.3.6.1.4.1.14519.5.2.1.6279.6001.179049373636438705059720603192',\n",
       " '1.3.6.1.4.1.14519.5.2.1.6279.6001.179049373636438705059720603192',\n",
       " '1.3.6.1.4.1.14519.5.2.1.6279.6001.179049373636438705059720603192',\n",
       " '1.3.6.1.4.1.14519.5.2.1.6279.6001.179049373636438705059720603192')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0][2], ds[1][2], ds[2][2], ds[3][2], ds[4][2], ds[5][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlwpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
