{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## p1. 拆解\"缓存准备.py\"文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../../src/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from util.util import enumerateWithEstimate\n",
    "from util.logconf import logging\n",
    "\n",
    "from p2ch11.dsets import LunaDataset\n",
    "from p2ch11.model import LunaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = logging.getLogger(__name__)\n",
    "# log.setLevel(logging.WARN)\n",
    "log.setLevel(logging.INFO)\n",
    "# log.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意需要修改p2ch11中dsets.py中的路径问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-28 17:43:13,535 INFO     pid:28724 p2ch11.dsets:197:__init__ <p2ch11.dsets.LunaDataset object at 0x0000020CC2292C90>: 110143 training samples\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_workers = 8\n",
    "\n",
    "prep_dl = DataLoader(\n",
    "    LunaDataset(\n",
    "        sortby_str=\"series_uid\",\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Started at {datetime.datetime.now()}\")\n",
    "# batch_iter = enumerateWithEstimate(\n",
    "#     prep_dl,\n",
    "#     \"Stuffing cache\",\n",
    "#     start_ndx=prep_dl.num_workers,\n",
    "# )\n",
    "# for _ in batch_iter:\n",
    "#     pass\n",
    "# print(f\"Finished at {datetime.datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## p2. 拆解train.py文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_workers = 8\n",
    "batch_size = 32\n",
    "epochs = 1\n",
    "tb_prefix = \"p2ch11\"\n",
    "comment = \"dlwpt\"\n",
    "\n",
    "time_str = datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "trn_writer = None\n",
    "val_writer = None\n",
    "total_training_samples = 0\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initModel():\n",
    "    model = LunaModel()\n",
    "    if use_cuda:\n",
    "        log.info(f\"Using CUDA; {torch.cuda.device_count()} devices.\")\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            model = nn.DataParallel(model)\n",
    "        model = model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initOptimizer():\n",
    "    return SGD(model.parameters(), lr=0.001, momentum=0.99)\n",
    "    # return Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initTrainDl(batch_size=64):\n",
    "    train_ds = LunaDataset(\n",
    "        val_stride=10,\n",
    "        isValSet_bool=False,\n",
    "    )\n",
    "\n",
    "    if use_cuda:\n",
    "        batch_size *= torch.cuda.device_count()\n",
    "\n",
    "    train_dl = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=use_cuda,\n",
    "    )\n",
    "\n",
    "    return train_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initValDl(batch_size=64):\n",
    "    val_ds = LunaDataset(\n",
    "        val_stride=10,\n",
    "        isValSet_bool=True,\n",
    "    )\n",
    "\n",
    "    if use_cuda:\n",
    "        batch_size *= torch.cuda.device_count()\n",
    "\n",
    "    val_dl = DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=use_cuda,\n",
    "    )\n",
    "\n",
    "    return val_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-28 18:04:28,279 INFO     pid:28724 __main__:004:initModel Using CUDA; 1 devices.\n",
      "2024-06-28 18:04:28,337 INFO     pid:28724 p2ch11.dsets:197:__init__ <p2ch11.dsets.LunaDataset object at 0x0000020CC046E480>: 99128 training samples\n",
      "2024-06-28 18:04:28,344 INFO     pid:28724 p2ch11.dsets:197:__init__ <p2ch11.dsets.LunaDataset object at 0x0000020CCD423E30>: 11015 validation samples\n"
     ]
    }
   ],
   "source": [
    "model = initModel()\n",
    "optimizer = initOptimizer()\n",
    "train_dl = initTrainDl()\n",
    "val_dl = initValDl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.设计训练方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = logging.getLogger(__name__)\n",
    "# log.setLevel(logging.WARN)\n",
    "log.setLevel(logging.INFO)\n",
    "log.setLevel(logging.DEBUG)\n",
    "\n",
    "# Used for computeBatchLoss and logMetrics to index into metrics_t/metrics_a\n",
    "METRICS_LABEL_NDX = 0\n",
    "METRICS_PRED_NDX = 1\n",
    "METRICS_LOSS_NDX = 2\n",
    "METRICS_SIZE = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeBatchLoss(batch_ndx, batch_tup, batch_size, metrics_g):\n",
    "    input_t, label_t, _series_list, _center_list = batch_tup\n",
    "\n",
    "    input_g = input_t.to(device, non_blocking=True)\n",
    "    label_g = label_t.to(device, non_blocking=True)\n",
    "\n",
    "    logits_g, probability_g = model(input_g)\n",
    "\n",
    "    loss_func = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "    loss_g = loss_func(\n",
    "        logits_g,\n",
    "        label_g[:, 1],\n",
    "    )\n",
    "    start_ndx = batch_ndx * batch_size\n",
    "    end_ndx = start_ndx + label_t.size(0)\n",
    "\n",
    "    metrics_g[METRICS_LABEL_NDX, start_ndx:end_ndx] = label_g[:, 1].detach()\n",
    "    metrics_g[METRICS_PRED_NDX, start_ndx:end_ndx] = probability_g[:, 1].detach()\n",
    "    metrics_g[METRICS_LOSS_NDX, start_ndx:end_ndx] = loss_g.detach()\n",
    "\n",
    "    return loss_g.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doTraining(epoch_ndx, train_dl, totalTrainingSamples_count=0):\n",
    "    model.train()\n",
    "    trnMetrics_g = torch.zeros(\n",
    "        METRICS_SIZE,\n",
    "        len(train_dl.dataset),\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    batch_iter = enumerateWithEstimate(\n",
    "        train_dl,\n",
    "        \"E{} Training\".format(epoch_ndx),\n",
    "        start_ndx=train_dl.num_workers,\n",
    "    )\n",
    "    for batch_ndx, batch_tup in batch_iter:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss_var = computeBatchLoss(\n",
    "            batch_ndx, batch_tup, train_dl.batch_size, trnMetrics_g\n",
    "        )\n",
    "\n",
    "        loss_var.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # # This is for adding the model graph to TensorBoard.\n",
    "        # if epoch_ndx == 1 and batch_ndx == 0:\n",
    "        #     with torch.no_grad():\n",
    "        #         model = LunaModel()\n",
    "        #         trn_writer.add_graph(model, batch_tup[0], verbose=True)\n",
    "        #         trn_writer.close()\n",
    "\n",
    "    totalTrainingSamples_count += len(train_dl.dataset)\n",
    "\n",
    "    return trnMetrics_g.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doValidation(epoch_ndx, val_dl):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        valMetrics_g = torch.zeros(\n",
    "            METRICS_SIZE,\n",
    "            len(val_dl.dataset),\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "        batch_iter = enumerateWithEstimate(\n",
    "            val_dl,\n",
    "            \"E{} Validation \".format(epoch_ndx),\n",
    "            start_ndx=val_dl.num_workers,\n",
    "        )\n",
    "        for batch_ndx, batch_tup in batch_iter:\n",
    "            computeBatchLoss(batch_ndx, batch_tup, val_dl.batch_size, valMetrics_g)\n",
    "\n",
    "    return valMetrics_g.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-28 18:10:57,106 INFO     pid:28724 __main__:003:<module> Epoch 1 of 1, 1549/173 batches of size 32*1\n",
      "2024-06-28 18:10:57,229 WARNING  pid:28724 util.util:219:enumerateWithEstimate E1 Training ----/1549, starting\n",
      "2024-06-28 18:11:41,463 INFO     pid:28724 util.util:236:enumerateWithEstimate E1 Training   64/1549, done at 2024-06-28 18:15:32, 0:03:59\n",
      "2024-06-28 18:12:10,971 INFO     pid:28724 util.util:236:enumerateWithEstimate E1 Training  256/1549, done at 2024-06-28 18:15:30, 0:03:57\n",
      "2024-06-28 18:14:11,504 INFO     pid:28724 util.util:236:enumerateWithEstimate E1 Training 1024/1549, done at 2024-06-28 18:15:33, 0:04:00\n",
      "2024-06-28 18:15:35,510 WARNING  pid:28724 util.util:249:enumerateWithEstimate E1 Training ----/1549, done at 2024-06-28 18:15:35\n",
      "2024-06-28 18:15:35,515 WARNING  pid:28724 util.util:219:enumerateWithEstimate E1 Validation  ----/173, starting\n",
      "2024-06-28 18:16:07,871 INFO     pid:28724 util.util:236:enumerateWithEstimate E1 Validation    64/173, done at 2024-06-28 18:16:11, 0:00:05\n",
      "2024-06-28 18:16:14,190 WARNING  pid:28724 util.util:249:enumerateWithEstimate E1 Validation  ----/173, done at 2024-06-28 18:16:14\n"
     ]
    }
   ],
   "source": [
    "for epoch_ndx in range(1, epochs + 1):\n",
    "\n",
    "    log.info(\n",
    "        \"Epoch {} of {}, {}/{} batches of size {}*{}\".format(\n",
    "            epoch_ndx,\n",
    "            epochs,\n",
    "            len(train_dl),\n",
    "            len(val_dl),\n",
    "            batch_size,\n",
    "            (torch.cuda.device_count() if use_cuda else 1),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    trnMetrics_t = doTraining(epoch_ndx, train_dl)\n",
    "    # logMetrics(epoch_ndx, 'trn', trnMetrics_t)\n",
    "\n",
    "    valMetrics_t = doValidation(epoch_ndx, val_dl)\n",
    "    # logMetrics(epoch_ndx, 'val', valMetrics_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlwpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
