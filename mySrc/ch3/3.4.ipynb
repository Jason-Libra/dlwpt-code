{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_t = torch.randn(3, 5, 5)  # shape [channels, rows, columns]\n",
    "weights = torch.tensor([0.2126, 0.7152, 0.0722])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0869, -0.9562,  0.5911,  0.2382,  1.1126],\n",
      "         [-1.4486, -0.4550,  1.8754, -0.9998, -0.0129],\n",
      "         [-0.5538,  0.4646,  0.4087, -1.0016, -0.9715],\n",
      "         [ 0.2246,  0.9119, -0.3628, -1.0283,  0.2119],\n",
      "         [-0.6576,  0.6554,  0.7890,  0.2821, -0.5278]],\n",
      "\n",
      "        [[ 1.0571, -0.6122, -0.5944,  0.9636, -0.1630],\n",
      "         [ 0.2059,  1.2749,  1.3276,  0.9712,  1.0257],\n",
      "         [ 1.1284,  0.6138,  1.5142,  0.5984,  0.9266],\n",
      "         [-1.0952, -1.8674,  0.9860,  0.1952, -0.5101],\n",
      "         [-0.2508,  1.5445, -0.9211,  1.0383, -0.1872]],\n",
      "\n",
      "        [[-0.6052, -0.3879, -0.4899, -0.1551,  1.0497],\n",
      "         [-0.2572,  0.4232, -0.6105, -0.7864,  0.0947],\n",
      "         [ 1.0499,  1.3242, -0.3187,  1.4906,  0.2694],\n",
      "         [ 0.3136, -0.7626,  0.0042, -0.2540, -1.6652],\n",
      "         [ 0.5921, -0.4410,  0.6714, -0.1353,  0.6119]]])\n"
     ]
    }
   ],
   "source": [
    "print(img_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-7.6417e-01, -2.0371e+00, -1.0506e+00,  3.1299e-01, -6.1085e-01],\n",
       "          [-5.1051e-02,  1.9981e-01,  3.0125e-01,  1.1571e+00, -7.1473e-02],\n",
       "          [ 1.3148e+00,  1.2980e+00,  2.9347e-02, -1.3969e+00,  2.2190e-01],\n",
       "          [-7.6489e-01,  8.4538e-01, -2.4829e-01,  1.0132e+00, -8.4737e-01],\n",
       "          [-1.3613e+00,  1.9013e+00,  1.3661e-01, -1.3891e+00,  1.5891e-01]],\n",
       "\n",
       "         [[-4.7915e-01,  1.2596e+00,  7.9482e-02,  7.5660e-01, -1.0671e+00],\n",
       "          [ 5.3922e-01,  7.6401e-01,  2.8260e+00, -1.4844e+00,  2.0199e-01],\n",
       "          [-8.0772e-01, -1.4622e-01,  1.7712e-01,  6.9754e-01, -3.1827e-01],\n",
       "          [ 1.8810e+00, -1.0554e+00,  3.9331e-01,  1.0228e+00, -4.1355e-01],\n",
       "          [ 1.6816e-01,  2.1946e-03, -2.8268e+00, -3.8403e-01, -1.1552e+00]],\n",
       "\n",
       "         [[ 4.9409e-01,  2.2540e+00,  4.7040e-01, -5.9877e-01,  6.8104e-01],\n",
       "          [ 5.0014e-01,  1.3215e-01, -4.0945e-01,  4.3848e-01,  1.3367e+00],\n",
       "          [-8.4992e-01,  4.9217e-01,  3.6789e-01, -1.0274e+00, -1.2600e+00],\n",
       "          [-1.4739e+00, -8.8313e-02, -3.0644e-01,  7.2157e-01,  1.2514e+00],\n",
       "          [ 6.5127e-04,  1.5650e+00,  7.6213e-01, -2.1063e-01,  1.2314e+00]]],\n",
       "\n",
       "\n",
       "        [[[-7.8253e-01,  8.8422e-01,  3.2652e-03,  4.1875e-01,  3.6376e-01],\n",
       "          [ 2.4048e-02, -7.5584e-01, -7.6107e-01,  6.0236e-01, -1.2105e-01],\n",
       "          [ 1.2911e-01,  1.2734e+00,  3.5656e-01, -4.6166e-01, -1.4358e+00],\n",
       "          [-1.2630e+00, -5.1303e-01, -1.8598e+00, -1.3416e+00, -2.8000e-01],\n",
       "          [ 1.5708e+00, -1.9063e-01,  8.9079e-01, -1.0394e+00, -3.5216e-01]],\n",
       "\n",
       "         [[-7.1894e-01, -7.9545e-01, -1.6559e-01, -5.5070e-01, -2.2816e-01],\n",
       "          [-1.5934e-01,  1.2680e+00,  4.6470e-01, -6.4562e-01,  4.3164e-01],\n",
       "          [ 1.9542e+00,  9.6659e-01,  3.9972e-01, -7.2322e-01, -9.2134e-02],\n",
       "          [ 1.0426e+00,  6.3832e-01,  1.2761e+00, -3.1435e+00, -3.6346e-01],\n",
       "          [-6.4785e-01,  7.3604e-01,  1.5331e+00,  2.0024e+00, -1.0186e+00]],\n",
       "\n",
       "         [[-8.7600e-01, -1.0074e+00,  5.9505e-02,  3.7876e-01,  6.5729e-01],\n",
       "          [ 9.2521e-01,  1.1689e+00, -8.8351e-01, -1.4457e+00, -3.7172e-01],\n",
       "          [ 1.0572e+00,  9.8293e-01,  1.5977e-01, -4.2011e-01, -1.5156e+00],\n",
       "          [ 8.4172e-02,  1.1424e+00, -9.0213e-02,  9.4599e-01,  9.0503e-01],\n",
       "          [ 5.8934e-01,  5.1095e-02,  1.1325e-01, -1.4972e+00,  7.7266e-01]]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_t = torch.randn(2, 3, 5, 5)  # shape [batch, channels, rows, columns]\n",
    "batch_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.,  1.,  2.,  3.,  4.],\n",
       "         [ 5.,  6.,  7.,  8.,  9.],\n",
       "         [10., 11., 12., 13., 14.],\n",
       "         [15., 16., 17., 18., 19.],\n",
       "         [20., 21., 22., 23., 24.]],\n",
       "\n",
       "        [[25., 26., 27., 28., 29.],\n",
       "         [30., 31., 32., 33., 34.],\n",
       "         [35., 36., 37., 38., 39.],\n",
       "         [40., 41., 42., 43., 44.],\n",
       "         [45., 46., 47., 48., 49.]],\n",
       "\n",
       "        [[50., 51., 52., 53., 54.],\n",
       "         [55., 56., 57., 58., 59.],\n",
       "         [60., 61., 62., 63., 64.],\n",
       "         [65., 66., 67., 68., 69.],\n",
       "         [70., 71., 72., 73., 74.]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a tensor of size (3, 5, 5) with values stored in natural number sequence\n",
    "img_t = torch.arange(75).reshape(3, 5, 5)\n",
    "\n",
    "img_t = img_t.float()\n",
    "img_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 5]) torch.Size([2, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "img_gray_naive = img_t.mean(-3)\n",
    "batch_gray_naive = batch_t.mean(-3)\n",
    "print(img_gray_naive.shape, batch_gray_naive.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[25., 26., 27., 28., 29.],\n",
       "        [30., 31., 32., 33., 34.],\n",
       "        [35., 36., 37., 38., 39.],\n",
       "        [40., 41., 42., 43., 44.],\n",
       "        [45., 46., 47., 48., 49.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_gray_naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 1, 1]),\n",
       " tensor([[[0.2126]],\n",
       " \n",
       "         [[0.7152]],\n",
       " \n",
       "         [[0.0722]]]),\n",
       " tensor([0.2126, 0.7152, 0.0722]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsqueezed_weights = weights.unsqueeze(-1).unsqueeze_(-1)\n",
    "unsqueezed_weights.shape, unsqueezed_weights, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 5, 5]), torch.Size([2, 3, 5, 5]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_weights = (img_t * unsqueezed_weights)\n",
    "batch_weights = (batch_t * unsqueezed_weights)\n",
    "img_weights.shape, batch_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlwpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
